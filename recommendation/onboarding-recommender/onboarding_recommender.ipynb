{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems\n",
    "\n",
    "Recommendation systems have revolutionized the way we discover and explore new things. These intelligent systems utilize sophisticated algorithms and data analysis to understand individual preferences and provide personalized recommendations. \n",
    "<br><br>\n",
    "By analyzing user data, such as **browsing history**, **purchase patterns**, and **social interactions**, recommendation systems can effectively predict and suggest items that align with users' interests. Whether it's suggesting a new movie to watch, a book to read, or a product to buy, these systems streamline decision-making and enhance the overall user experience. \n",
    "<br>\n",
    "With their ability to uncover hidden gems and introduce users to exciting possibilities, recommendation systems have become invaluable tools in navigating the overwhelming abundance of choices in today's digital landscape.\n",
    "\n",
    "### Recommendation Systems and Vector Databases\n",
    "\n",
    "In recommendation systems, understanding the similarity between users and items is crucial for generating accurate and personalized recommendations. By leveraging vector databases, these systems can store and organize user and item vectors, which capture the essential characteristics and preferences associated with each user and item. \n",
    "<br><br>\n",
    "The vector database employs <a href=\"https://www.pinecone.io/learn/vector-database/#:~:text=a%20vector%20database.-,Algorithms,-Several%20algorithms%20can\">advanced indexing techniques</a>, to enable fast retrieval of **similar users or items** based on their **vector representations**. This enables recommendation systems to efficiently process *large-scale datasets* and identify meaningful connections, leading to more precise and relevant recommendations. \n",
    "<br><br>\n",
    "By harnessing the power of vector databases, such as **Pinecone**, recommendation systems can optimize their performance, enhance user satisfaction, and deliver tailored experiences that align with individual preferences.\n",
    "<br><br><br>\n",
    "Let's take a look at how we can implement one of those use cases!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by installing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    \"pinecone-client[grpc]\"==2.2.1 \\\n",
    "    pinecone-datasets \\\n",
    "    transformers \\\n",
    "    tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ðŸš¨ _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "<img alt=\"Onboarding recommender diagram\" src=\"https://github.com/pinecone-io/examples/blob/onboarding-recommender/recommendation/onboarding-recommender/assets/onboarding_recommender_data_flow.jpg\"  width=\"70%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the Dataset\n",
    "\n",
    "We will download a pre-embedding dataset from `pinecone-datasets`. Allowing us to skip the embedding and any other preprocessing steps. \n",
    "<br><br>\n",
    "When working with your own dataset you will need to perform this embedding step but we have prebuilt the embeddings so we can jump right to the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"movielens-user-ratings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting the Dataset\n",
    "\n",
    "A `pinecone-dataset` always contains `id`, `values`, `sparse_values`, `metadata`, and `blob`. All we need are the IDs, vector embeddings (stored in `values`), and some metadata (which is actually stored in `blob`). Let's reformat the dataset ready for adding to Pinecone. We also drop `sparse_values` as they are not needed for this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.documents.drop(['sparse_values', 'metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the metadata value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "\n",
    "pp(dataset.documents['metadata'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move on to initializing our Pinecone vector database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set `PINECONE_API_KEY` and `PINECONE_ENV` variables that we are going to use during initialization step. You can find these values in [Pinecone Console](https://app.pinecone.io/) in the API Keys section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
    "PINECONE_ENV = os.environ.get('PINECONE_ENVIRONMENT') or 'PINECONE_ENVIRONMENT'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these variables for initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a new index, we need to specify the index name, similarity metric, as well as the dimension of the vectors stored in that index. \n",
    "<br>\n",
    "We will assign these values here. \n",
    "<br>\n",
    "Note that the dimension parameter has to match the embedding dimensions provided in the dataset (or the model that outputs those embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding dimensions\n",
    "len(dataset.documents['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'onboarding-recommender'\n",
    "SIM_METRIC = 'cosine'\n",
    "DIMENSION = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to check if the index already exists. In this example, we will delete it and create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INDEX_NAME in pinecone.list_indexes():\n",
    "    pinecone.delete_index(INDEX_NAME)\n",
    "\n",
    "pinecone.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    metric=SIM_METRIC,\n",
    "    dimension=DIMENSION,\n",
    ")\n",
    "# wait a moment for the index to be fully initialized\n",
    "time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to initialize an index variable so that we can use it later on to describe the index and perform vector upsert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_index = pinecone.GRPCIndex(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_index.upsert_from_dataframe(dataset.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when the index is populated, we can perform queries on it to find the most relevant recommendations.\n",
    "<br>\n",
    "To do that, we need to instantiate our embedding models so that we can create vectors from our input user or input item objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Model\n",
    "\n",
    "We will download the models from the HuggingFace Hub. We will use one model to embed the *example user* and another model to embed the *example item*. <br>\n",
    "This will allow us to retrieve the most relevant items for a specific user or find the most similar items to a specific item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "\n",
    "user_model = from_pretrained_keras(\"pinecone/movie-recommender-user-model\")\n",
    "movie_model = from_pretrained_keras(\"pinecone/movie-recommender-movie-model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we can create a `movie_details` dataset that we can use later on to print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_details = pd.DataFrame(dataset.documents['metadata'].values.tolist())\n",
    "movies_details.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can check how our vector database behaves when returning the most similar movies upon querying it using the movie vector created using the `movie_model` loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1263  # you can try experimenting with different movie ids to obtain different results, for example 3571\n",
    "movie_vector = movie_model(movie_id).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_details[movies_details['movie_id'] == movie_id]['title'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_query_results = grpc_index.query(queries=[movie_vector], top_k=10, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in movie_query_results.results:\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'movies': [match.metadata['title'] for match in res.matches],\n",
    "            'scores': [match.score for match in res.matches]\n",
    "        }\n",
    "    )\n",
    "    print(\"Recommendations: \")\n",
    "    display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that it is doing an excellent job in finding similar movies, and it is accomplishing this task very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's observe how our vector database behaves when we query it using the user vector.\n",
    "<br>\n",
    "We expect to receive movies that closely resemble the ones that the user rated highly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 3\n",
    "user_vector = user_model(user_id).numpy().tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are defining a function that allows us to easily display the movies that the user rated in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_movies_user_rated(user):\n",
    "    # get list of movies that the user has rated\n",
    "    user_movies = movies_details[movies_details[\"user_id\"] == user]\n",
    "    # order by their top rated movies\n",
    "    top_rated = user_movies.sort_values(by=['rating'], ascending=False)\n",
    "    # return the top 14 movies\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'movies': top_rated['title'].tolist()[:14],\n",
    "            'ratings': top_rated['rating'].tolist()[:14]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_movies_user_rated(user_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can pass our `user_vector` to the query to get the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = grpc_index.query(queries=[user_vector], top_k=10, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in query_results.results:\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'movies': [match.metadata['title'] for match in res.matches],\n",
    "            'scores': [match.score for match in res.matches]\n",
    "        }\n",
    "    )\n",
    "    print(\"Recommendations: \")\n",
    "    display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can observe that these recommendations strongly resemble the movies that the user rated highly, and there are no movies similar to the ones that the user rated with a low value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The notebook demonstrated the step-by-step process of creating and populating an index in the vector database. It covered aspects such as specifying the index name, similarity metric, and vector dimensions. The example also included instructions on checking if an index exists, deleting and creating new indexes when necessary.\n",
    "\n",
    "Furthermore, the notebook illustrated the usage of embedding models to generate vector representations of both users and items. The results showed that the recommendations closely resembled the movies that the user rated highly, and dissimilar movies were not included.\n",
    "\n",
    "Overall, this example showcased the power and efficiency of vector databases in recommendation systems. It is important to note that the benefits of vector databases extend beyond movies and can be applied to various types of items, making them a valuable tool in building effective recommendation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone-onboarding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
